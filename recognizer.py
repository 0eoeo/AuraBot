import os
import base64
import tempfile
import asyncio
from typing import Optional

from fastapi import FastAPI, Request, BackgroundTasks, Header
from fastapi.responses import FileResponse, JSONResponse
from pydub import AudioSegment
from dotenv import load_dotenv

import whisper
import torch

from generate_answer import BotState
from voice import create_voice_answer

load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN")
device = "cuda" if torch.cuda.is_available() else "cpu"
model = whisper.load_model("tiny", device=device)

app = FastAPI()

blocked_phrases = [
    "–¥–∏–Ω–∞–º–∏—á–Ω–∞—è –º—É–∑—ã–∫–∞", "—Ä–µ–¥–∞–∫—Ç–æ—Ä —Å—É–±—Ç–∏—Ç—Ä–æ–≤", "—Å–∏–ª—å–Ω—ã–π —à—É–º",
    "–±–µ–∑ –∑–≤—É–∫–∞", "–º—É–∑—ã–∫–∞–ª—å–Ω–∞—è –∑–∞—Å—Ç–∞–≤–∫–∞", "–∞—Ö –∞—Ö –∞—Ö"
]


def decode_speaker_name(encoded_name: Optional[str]) -> str:
    if not encoded_name:
        return "–ë—Ä–æ"
    try:
        return base64.b64decode(encoded_name).decode("utf-8")
    except Exception:
        return "–ë—Ä–æ"


def cleanup(paths):
    for path in paths:
        try:
            if path and os.path.exists(path):
                os.remove(path)
                print(f"üóëÔ∏è –£–¥–∞–ª—ë–Ω —Ñ–∞–π–ª: {path}")
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {path}: {e}")


async def generate_voice_answer(bot: BotState, context_version: int):
    await asyncio.sleep(1.0)
    if bot.context_version != context_version:
        print("‚è© –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑–º–µ–Ω–∏–ª—Å—è ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞")
        return

    print("üß† –ì–µ–Ω–µ—Ä–∏—Ä—É—é –≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç")
    text = bot.get_response_text()
    if not text:
        print("‚ö†Ô∏è –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç GigaChat")
        return

    output_path = "output.wav"
    path = create_voice_answer(text, device=device)

    if path and os.path.exists(path):
        print(f"‚úÖ –û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {output_path}")
    else:
        print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∞—É–¥–∏–æ")


@app.post("/recognize")
async def recognize_audio(
    request: Request,
    background_tasks: BackgroundTasks,
    x_speaker_name: Optional[str] = Header(None)
):
    speaker = decode_speaker_name(x_speaker_name)
    print(f"üì• –ó–∞–ø—Ä–æ—Å –æ—Ç: {speaker}")

    body = await request.body()
    if not body:
        return JSONResponse(content={"error": "–ù–µ—Ç –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö"}, status_code=400)

    with tempfile.NamedTemporaryFile(delete=False, suffix=".pcm") as tmp_pcm:
        tmp_pcm.write(body)
        pcm_path = tmp_pcm.name

    wav_path = pcm_path + ".wav"

    try:
        pcm_audio = AudioSegment.from_file(
            pcm_path, format="raw", frame_rate=48000, channels=2, sample_width=2
        )
        pcm_audio.export(wav_path, format="wav")
    except Exception as e:
        print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ PCM:", e)
        cleanup([pcm_path])
        return JSONResponse(content={"error": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ PCM"}, status_code=500)

    if len(pcm_audio) < 500:
        print("‚ö†Ô∏è –ê—É–¥–∏–æ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ")
        cleanup([pcm_path, wav_path])
        return JSONResponse(content={"error": "–ê—É–¥–∏–æ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ"}, status_code=204)

    result = model.transcribe(wav_path, language="ru")
    text = result.get("text", "").strip()
    print(f"üìù {speaker}: {text}")

    cleanup([pcm_path, wav_path])

    if not text:
        return JSONResponse(content={"error": "–ü—É—Å—Ç–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è"}, status_code=204)

    if any(phrase in text.lower() for phrase in blocked_phrases):
        print("‚õî –°—Ç–æ–ø-—Ñ—Ä–∞–∑–∞. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
        return JSONResponse(content={"message": "–°—Ç–æ–ø-—Ñ—Ä–∞–∑–∞"}, status_code=204)

    bot = BotState(credentials=BOT_TOKEN)
    bot.append_context(f"{speaker}: {text}")
    background_tasks.add_task(generate_voice_answer, bot, bot.context_version)

    # –ü—ã—Ç–∞–µ–º—Å—è –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –µ—Å–ª–∏ –µ—Å—Ç—å
    if os.path.exists("output.wav"):
        print("üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ output.wav")
        response = FileResponse("output.wav", media_type="audio/wav", filename="response.wav")
        background_tasks.add_task(cleanup, ["output.wav"])
        return response

    return JSONResponse(content={"message": "–û–∂–∏–¥–∞–µ–º –æ—Ç–≤–µ—Ç"}, status_code=204)
