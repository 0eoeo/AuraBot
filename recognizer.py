import os
import torch
from fastapi import FastAPI, BackgroundTasks, HTTPException, Request
from pydub import AudioSegment
import tempfile
import whisper
from dotenv import load_dotenv
from TTS.api import TTS
import base64

from voice import create_voice_answer

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env
load_dotenv()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI
app = FastAPI()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ Whisper –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏
device = "cuda" if torch.cuda.is_available() else "cpu"
model = whisper.load_model("tiny", device=device)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ—á–∏
torch.serialization.add_safe_globals(["XttsConfig", "XttsAudioConfig", "BaseDatasetConfig", "XttsArgs"])
tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v2")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
blocked_phrases = [
    "–¥–∏–Ω–∞–º–∏—á–Ω–∞—è –º—É–∑—ã–∫–∞", "—Ä–µ–¥–∞–∫—Ç–æ—Ä —Å—É–±—Ç–∏—Ç—Ä–æ–≤", "—Å–∏–ª—å–Ω—ã–π —à—É–º",
    "–±–µ–∑ –∑–≤—É–∫–∞", "–º—É–∑—ã–∫–∞–ª—å–Ω–∞—è –∑–∞—Å—Ç–∞–≤–∫–∞", "–∞—Ö –∞—Ö –∞—Ö"
]

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–º–µ–Ω–∏ –≥–æ–≤–æ—Ä—è—â–µ–≥–æ
def decode_speaker_name(encoded_name):
    try:
        return base64.b64decode(encoded_name).decode("utf-8")
    except Exception:
        return "–ë—Ä–æ"

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
def cleanup(paths):
    for path in paths:
        try:
            if path and os.path.exists(path):
                os.remove(path)
                print(f"üóëÔ∏è –£–¥–∞–ª—ë–Ω —Ñ–∞–π–ª: {path}")
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {path}: {e}")

@app.post("/recognize")
async def recognize(request: Request, background_tasks: BackgroundTasks):
    speaker_b64 = request.headers.get("X-Speaker-Name")
    speaker = decode_speaker_name(speaker_b64) if speaker_b64 else "–ë—Ä–æ"

    print(f"üì• –ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ—Ç {speaker}")
    audio_data = await request.body()  # –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–æ–ª—É—á–∞–µ–º —Ç–µ–ª–æ –∑–∞–ø—Ä–æ—Å–∞
    if not audio_data:
        raise HTTPException(status_code=400, detail="No audio data provided")

    with tempfile.NamedTemporaryFile(delete=False, suffix=".pcm") as tmp_pcm:
        pcm_path = tmp_pcm.name
        tmp_pcm.write(audio_data)

    wav_path = pcm_path + ".wav"

    pcm_audio = AudioSegment.from_file(
        pcm_path,
        format="raw",
        frame_rate=48000,
        channels=2,
        sample_width=2
    )
    pcm_audio.export(wav_path, format="wav")

    if len(pcm_audio) < 500:
        print("‚ö†Ô∏è –ê—É–¥–∏–æ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
        cleanup([pcm_path, wav_path])
        return '', 204

    if not os.path.exists(wav_path):
        print("‚ùå WAV-—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ—Å–ª–µ —ç–∫—Å–ø–æ—Ä—Ç–∞")
        cleanup([pcm_path])
        raise HTTPException(status_code=500, detail="WAV-—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")

    # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
    result = model.transcribe(wav_path, language="ru")
    text = result.get('text', '').strip()
    print(f"üìù {speaker}: {text}")

    if not text:
        cleanup([pcm_path, wav_path])
