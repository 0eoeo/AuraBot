import os
import torch
from fastapi import FastAPI, BackgroundTasks, HTTPException, Request
from fastapi.responses import FileResponse
from pydub import AudioSegment
import tempfile
import whisper
from dotenv import load_dotenv
import base64

from voice import create_voice_answer
from generate_answer import BotState

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env
load_dotenv()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI
app = FastAPI()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ Whisper –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏
device = "cuda" if torch.cuda.is_available() else "cpu"
model = whisper.load_model("tiny", device=device)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
blocked_phrases = [
    "–¥–∏–Ω–∞–º–∏—á–Ω–∞—è –º—É–∑—ã–∫–∞", "—Ä–µ–¥–∞–∫—Ç–æ—Ä —Å—É–±—Ç–∏—Ç—Ä–æ–≤", "—Å–∏–ª—å–Ω—ã–π —à—É–º",
    "–±–µ–∑ –∑–≤—É–∫–∞", "–º—É–∑—ã–∫–∞–ª—å–Ω–∞—è –∑–∞—Å—Ç–∞–≤–∫–∞", "–∞—Ö –∞—Ö –∞—Ö"
]

giga_chat_context = BotState()

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–º–µ–Ω–∏ –≥–æ–≤–æ—Ä—è—â–µ–≥–æ
def decode_speaker_name(encoded_name):
    try:
        return base64.b64decode(encoded_name).decode("utf-8")
    except Exception:
        return "–ë—Ä–æ"

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
def cleanup(paths):
    for path in paths:
        try:
            if path and os.path.exists(path):
                os.remove(path)
                print(f"üóëÔ∏è –£–¥–∞–ª—ë–Ω —Ñ–∞–π–ª: {path}")
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {path}: {e}")

@app.post("/recognize")
async def recognize(request: Request, background_tasks: BackgroundTasks):
    speaker_b64 = request.headers.get("X-Speaker-Name")
    speaker = decode_speaker_name(speaker_b64) if speaker_b64 else "–ë—Ä–æ"

    print(f"üì• –ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ—Ç {speaker}")
    audio_data = await request.body()
    if not audio_data:
        raise HTTPException(status_code=400, detail="No audio data provided")

    with tempfile.NamedTemporaryFile(delete=False, suffix=".pcm") as tmp_pcm:
        pcm_path = tmp_pcm.name
        tmp_pcm.write(audio_data)

    wav_path = pcm_path + ".wav"

    pcm_audio = AudioSegment.from_file(
        pcm_path,
        format="raw",
        frame_rate=48000,
        channels=2,
        sample_width=2
    )
    pcm_audio.export(wav_path, format="wav")

    if len(pcm_audio) < 500:
        print("‚ö†Ô∏è –ê—É–¥–∏–æ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
        cleanup([pcm_path, wav_path])
        return '', 204

    if not os.path.exists(wav_path):
        print("‚ùå WAV-—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ—Å–ª–µ —ç–∫—Å–ø–æ—Ä—Ç–∞")
        cleanup([pcm_path])
        raise HTTPException(status_code=500, detail="WAV-—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")

    # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
    result = model.transcribe(wav_path, language="ru")
    text = result.get('text', '').strip()
    print(f"üìù {speaker}: {text}")

    if not text:
        cleanup([pcm_path, wav_path])
        return '', 204

    # –ü—Ä–∏–≤–æ–¥–∏–º —Ç–µ–∫—Å—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    lower_text = text.lower()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç –±–ª–æ–∫-—Ñ—Ä–∞–∑—ã
    if any(phrase in lower_text for phrase in blocked_phrases):
        print("üö´ –ù–∞–π–¥–µ–Ω–∞ –±–ª–æ–∫-—Ñ—Ä–∞–∑–∞. –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏ –æ—Ç–≤–µ—Ç –Ω–µ –±—É–¥—É—Ç –æ–±–Ω–æ–≤–ª–µ–Ω—ã.")
        cleanup([pcm_path, wav_path])
        return '', 204

    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    giga_chat_context.append_context(text)

    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –±–æ—Ç–∞
    response_text = giga_chat_context.get_response_text()
    if not response_text:
        cleanup([pcm_path, wav_path])
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –±–æ—Ç–∞")

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
    output_path = create_voice_answer(response_text, device=device)

    if output_path:
        background_tasks.add_task(cleanup, [pcm_path, wav_path, output_path])
        return FileResponse(output_path, media_type="audio/wav", filename="response.wav")
    else:
        cleanup([pcm_path, wav_path])
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ –æ—Ç–≤–µ—Ç–∞")
