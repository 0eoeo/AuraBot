import os
import torch
import numpy as np
from fastapi import FastAPI, BackgroundTasks, HTTPException, Request
from fastapi.responses import StreamingResponse
import whisper
from dotenv import load_dotenv
import base64
import concurrent.futures
from voice import create_voice_answer
from generate_answer import BotState
from scipy.signal import resample

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI
app = FastAPI()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ Whisper
device = "cuda" if torch.cuda.is_available() else "cpu"
model = whisper.load_model("tiny", device=device)
result = whisper.transcribe('–Ω—è—Ä—É.wav')
print('–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≥—Ä–µ–≤–∞: ', result["text"])

# –ü—É–ª –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è —Ç—è–∂—ë–ª—ã—Ö –∑–∞–¥–∞—á
executor = concurrent.futures.ThreadPoolExecutor()

# –ö–æ–Ω—Ç–µ–∫—Å—Ç GigaChat
giga_chat_context = BotState()

# –ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã
blocked_phrases = {"–¥–∏–Ω–∞–º–∏—á–Ω–∞—è –º—É–∑—ã–∫–∞", "—Ä–µ–¥–∞–∫—Ç–æ—Ä —Å—É–±—Ç–∏—Ç—Ä–æ–≤", "—Å–∏–ª—å–Ω—ã–π —à—É–º",
                   "–±–µ–∑ –∑–≤—É–∫–∞", "–º—É–∑—ã–∫–∞–ª—å–Ω–∞—è –∑–∞—Å—Ç–∞–≤–∫–∞", "–∞—Ö –∞—Ö –∞—Ö", "–∞–ø–ª–æ–¥–∏—Å–º–µ–Ω—Ç—ã",
                   "—É—Ö —É—Ö —É—Ö", "—Ö–∞ —Ö–∞ —Ö–∞", "—Å–º–µ—Ö", "—Å–ø–æ–∫–æ–π–Ω–∞—è –º—É–∑—ã–∫–∞"}


def decode_speaker_name(encoded_name: str) -> str:
    try:
        return base64.b64decode(encoded_name).decode("utf-8")
    except Exception:
        return "–ë—Ä–æ"


# –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
def cleanup(paths):
    for path in paths:
        try:
            if path and os.path.exists(path):
                os.remove(path)
                print(f"üóëÔ∏è –£–¥–∞–ª—ë–Ω —Ñ–∞–π–ª: {path}")
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {path}: {e}")


# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ
def normalize_audio(audio_np: np.ndarray):
    max_val = np.max(np.abs(audio_np))
    if max_val > 0:
        audio_np = audio_np / max_val  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç -1 –¥–æ 1
    return audio_np


# –†–µ—Å–µ–º–ø–ª–∏–Ω–≥ –∞—É–¥–∏–æ
def resample_audio(audio_np: np.ndarray, target_rate: int, current_rate: int):
    num_samples = round(len(audio_np) * float(target_rate) / current_rate)
    resampled_audio = resample(audio_np, num_samples)
    return resampled_audio


# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏
async def transcribe_audio(model, audio_np: np.ndarray):
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç, –∫–æ—Ç–æ—Ä—ã–π –≤–æ—Å–ø—Ä–∏–Ω–∏–º–∞–µ—Ç Whisper
    audio_np = normalize_audio(audio_np)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
    audio_np = audio_np.astype(np.float32)

    # –ï—Å–ª–∏ –∞—É–¥–∏–æ —Å —á–∞—Å—Ç–æ—Ç–æ–π –Ω–µ 16000 –ì—Ü, –Ω—É–∂–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Ä–µ—Å–µ–º–ø–ª–∏–Ω–≥
    current_rate = 48000  # –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ –∏–∑–Ω–∞—á–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ 48000 –ì—Ü
    target_rate = 16000  # –¶–µ–ª–µ–≤–∞—è —á–∞—Å—Ç–æ—Ç–∞ –¥–ª—è Whisper
    if current_rate != target_rate:
        audio_np = resample_audio(audio_np, target_rate, current_rate)

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
    audio_tensor = torch.from_numpy(audio_np).to(device)

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º Whisper –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–∏—è
    result = model.transcribe(audio_tensor)
    return result


# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
async def generate_voice_answer(text: str):
    output_path = await create_voice_answer(text)
    if output_path:
        return output_path
    return None


# –û—Å–Ω–æ–≤–Ω–æ–π —Ä—É—Ç –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏
@app.post("/recognize")
async def recognize(request: Request, background_tasks: BackgroundTasks):
    speaker_b64 = request.headers.get("X-Speaker-Name")
    speaker = decode_speaker_name(speaker_b64) if speaker_b64 else "–ë—Ä–æ"

    print(f"üì• –ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ—Ç {speaker}")

    audio_data = await request.body()
    if not audio_data:
        raise HTTPException(status_code=400, detail="No audio data provided")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–ª–∏–Ω—É –¥–∞–Ω–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, 0.5 —Å–µ–∫)
    min_pcm_bytes = int(48000 * 2 * 2 * 0.5)  # 48000 samples/sec * 2 bytes/sample * 2 channels * 0.5 sec
    if len(audio_data) < min_pcm_bytes:
        print("‚ö†Ô∏è –ê—É–¥–∏–æ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
        return '', 204

    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ raw PCM –≤ numpy
    try:
        audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ [-1, 1]
        audio_np = audio_np.reshape(-1, 2).mean(axis=1)  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç–µ—Ä–µ–æ –≤ –º–æ–Ω–æ
        audio_np = normalize_audio(audio_np)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ: {e}")
        raise HTTPException(status_code=400, detail="–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∞—É–¥–∏–æ—Ñ–æ—Ä–º–∞—Ç")

    # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
    try:
        result = await transcribe_audio(model, audio_np)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏")

    recognized_text = result.get('text', '').strip()
    if not recognized_text:
        print("‚ö†Ô∏è –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø—É—Å—Ç–æ–π.")
        return '', 204

    full_text = f"[{speaker}]: {recognized_text}"
    print(f"üìù {full_text}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –±–ª–æ–∫-—Ñ—Ä–∞–∑—ã
    lower_text = full_text.lower()
    if any(phrase in lower_text for phrase in blocked_phrases):
        print("üö´ –ù–∞–π–¥–µ–Ω–∞ –±–ª–æ–∫-—Ñ—Ä–∞–∑–∞. –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏ –æ—Ç–≤–µ—Ç –Ω–µ –±—É–¥—É—Ç –æ–±–Ω–æ–≤–ª–µ–Ω—ã.")
        return '', 204

    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
    giga_chat_context.append_context(full_text)

    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç GigaChat —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–ª–∏ –≤–æ–ø—Ä–æ—Å
    if "–∑–∞–Ω–∏" in full_text.lower() or "?" in full_text:
        response_text = giga_chat_context.get_response_text()
        if not response_text:
            cleanup([audio_data])
            raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –±–æ—Ç–∞")

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        output_path = await generate_voice_answer(response_text)

        if output_path:
            background_tasks.add_task(cleanup, [audio_data, output_path])

            # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –ø–æ —á–∞—Å—Ç—è–º –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–π –ø–µ—Ä–µ–¥–∞—á–∏
            def iterfile():
                with open(output_path, mode="rb") as f:
                    while chunk := f.read(1024):  # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –∫—É—Å–∫–∞–º–∏ –ø–æ 1024 –±–∞–π—Ç–∞
                        yield chunk

            return StreamingResponse(iterfile(), media_type="audio/wav",
                                     headers={"Content-Disposition": "attachment; filename=response.wav"})

    # –ï—Å–ª–∏ —Å–ª–æ–≤–æ "–∑–∞–Ω–∏" –∏–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ –Ω–∞–π–¥–µ–Ω, –Ω–∏—á–µ–≥–æ –Ω–µ –æ—Ç–≤–µ—á–∞–µ–º
    print("üîé –û–±—Ä–∞—â–µ–Ω–∏–µ '–ó–∞–Ω–∏' –∏–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –û—Ç–≤–µ—Ç –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
    return '', 204
