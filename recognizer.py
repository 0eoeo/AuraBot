import os
import torch
import numpy as np
from fastapi import FastAPI, BackgroundTasks, HTTPException, Request
from fastapi.responses import FileResponse
import whisper
from dotenv import load_dotenv
import base64
import asyncio
import concurrent.futures

from voice import create_voice_answer
from generate_answer import BotState

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI
app = FastAPI()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ Whisper
device = "cuda" if torch.cuda.is_available() else "cpu"
model = whisper.load_model("tiny", device=device)

# –ü—É–ª –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è —Ç—è–∂—ë–ª—ã—Ö –∑–∞–¥–∞—á
executor = concurrent.futures.ThreadPoolExecutor()

# –ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã
blocked_phrases = {
    "–¥–∏–Ω–∞–º–∏—á–Ω–∞—è –º—É–∑—ã–∫–∞", "—Ä–µ–¥–∞–∫—Ç–æ—Ä —Å—É–±—Ç–∏—Ç—Ä–æ–≤", "—Å–∏–ª—å–Ω—ã–π —à—É–º",
    "–±–µ–∑ –∑–≤—É–∫–∞", "–º—É–∑—ã–∫–∞–ª—å–Ω–∞—è –∑–∞—Å—Ç–∞–≤–∫–∞", "–∞—Ö –∞—Ö –∞—Ö",
    "–∞–ø–ª–æ–¥–∏—Å–º–µ–Ω—Ç—ã", "—É—Ö —É—Ö —É—Ö", "—Ö–∞ —Ö–∞ —Ö–∞", "—Å–º–µ—Ö"
}

# –ö–æ–Ω—Ç–µ–∫—Å—Ç GigaChat
giga_chat_context = BotState()


def decode_speaker_name(encoded_name: str) -> str:
    try:
        return base64.b64decode(encoded_name).decode("utf-8")
    except Exception:
        return "–ë—Ä–æ"


def cleanup(paths):
    for path in paths:
        try:
            if path and os.path.exists(path):
                os.remove(path)
                print(f"üóëÔ∏è –£–¥–∞–ª—ë–Ω —Ñ–∞–π–ª: {path}")
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {path}: {e}")


async def transcribe_audio(model, audio_np: np.ndarray):
    loop = asyncio.get_running_loop()
    return await loop.run_in_executor(executor, lambda: model.transcribe(audio_np, language="ru"))


@app.post("/recognize")
async def recognize(request: Request, background_tasks: BackgroundTasks):
    # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–º–µ–Ω–∏ —Å–ø–∏–∫–µ—Ä–∞
    speaker_b64 = request.headers.get("X-Speaker-Name")
    speaker = decode_speaker_name(speaker_b64) if speaker_b64 else "–ë—Ä–æ"

    print(f"üì• –ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ—Ç {speaker}")

    # –ß—Ç–µ–Ω–∏–µ —Ç–µ–ª–∞ –∑–∞–ø—Ä–æ—Å–∞
    audio_data = await request.body()
    if not audio_data:
        raise HTTPException(status_code=400, detail="No audio data provided")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ (–ø—Ä–∏–º–µ—Ä–Ω–æ 0.5 —Å–µ–∫—É–Ω–¥—ã)
    min_pcm_bytes = int(48000 * 2 * 2 * 0.5)
    if len(audio_data) < min_pcm_bytes:
        print("‚ö†Ô∏è –ê—É–¥–∏–æ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
        return '', 204

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è raw PCM -> numpy
    try:
        audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0
        audio_np = audio_np.reshape(-1, 2).mean(axis=1)  # –°—Ç–µ—Ä–µ–æ –≤ –º–æ–Ω–æ
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ: {e}")
        raise HTTPException(status_code=400, detail="–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∞—É–¥–∏–æ—Ñ–æ—Ä–º–∞—Ç")

    # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏
    try:
        result = await transcribe_audio(model, audio_np)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏")

    recognized_text = result.get('text', '').strip()
    if not recognized_text:
        print("‚ö†Ô∏è –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø—É—Å—Ç–æ–π.")
        return '', 204

    full_text = f"[{speaker}]: {recognized_text}"
    print(f"üìù {full_text}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –±–ª–æ–∫-—Ñ—Ä–∞–∑—ã
    lower_text = full_text.lower()
    if any(phrase in lower_text for phrase in blocked_phrases):
        print("üö´ –ù–∞–π–¥–µ–Ω–∞ –±–ª–æ–∫-—Ñ—Ä–∞–∑–∞. –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏ –æ—Ç–≤–µ—Ç –Ω–µ –±—É–¥—É—Ç –æ–±–Ω–æ–≤–ª–µ–Ω—ã.")
        return '', 204

    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    giga_chat_context.append_context(full_text)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞-–æ—Ç–≤–µ—Ç–∞
    response_text = giga_chat_context.get_response_text()
    if not response_text:
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –±–æ—Ç–∞")

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
    output_path = await create_voice_answer(response_text)
    if not output_path:
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ –æ—Ç–≤–µ—Ç–∞")

    # –ü–ª–∞–Ω–∏—Ä—É–µ–º —Ñ–æ–Ω–æ–≤—É—é –æ—á–∏—Å—Ç–∫—É —Ñ–∞–π–ª–æ–≤
    background_tasks.add_task(cleanup, [output_path])

    return FileResponse(output_path, media_type="audio/wav", filename="response.wav")
